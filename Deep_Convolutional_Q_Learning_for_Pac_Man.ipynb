{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-1945/Deep_QLearning_for_Pacman/blob/main/Deep_Convolutional_Q_Learning_for_Pac_Man.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Convolutional Q-Learning for Pac-Man"
      ],
      "metadata": {
        "id": "EAiHVEoWHy_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0 - Installing the required packages and importing the libraries"
      ],
      "metadata": {
        "id": "tjO1aK3Ddjs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Gymnasium"
      ],
      "metadata": {
        "id": "NwdRB-ZLdrAV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbnq3XpoKa_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834eb314-2713-409a-9dae-58746656b8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2 (from gymnasium[accept-rom-license,atari])\n",
            "  Using cached AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting shimmy[atari]<1.0,>=0.1.0 (from gymnasium[accept-rom-license,atari])\n",
            "  Using cached Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (4.66.4)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari])\n",
            "  Using cached AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]) (6.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2024.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=63b077edf95d2afe49f6a8c5b986eebb14385a9eb6eec28c78ec3ea9627f4df9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: ale-py, shimmy, AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.4.2 shimmy-0.2.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 0s (2,521 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Collecting swig==4.* (from gymnasium[box2d])\n",
            "  Using cached swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2349139 sha256=9847f7160e3d2380528e60950de81af879fdb18abde6a3133df046bae45ba9a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: swig, box2d-py\n",
            "Successfully installed box2d-py-2.3.5 swig-4.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install \"gymnasium[atari, accept-rom-license]\"\n",
        "!apt-get install -y swig\n",
        "!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries"
      ],
      "metadata": {
        "id": "H-wes4LZdxdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho_25-9_9qnu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Building the AI"
      ],
      "metadata": {
        "id": "m7wa0ft8e3M_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the architecture of the Neural Network"
      ],
      "metadata": {
        "id": "dlYVpVdHe-i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self,action_size,seed = 42):\n",
        "    super(Network,self).__init__()\n",
        "    self.seed = torch.manual_seed(seed)\n",
        "    self.conv1 = nn.Conv2d(3,32,kernel_size = 8, stride = 4)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "    self.conv2 = nn.Conv2d(32,64,kernel_size = 4, stride = 2)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "    self.conv3 = nn.Conv2d(64,64,kernel_size = 3, stride = 1)\n",
        "    self.bn3 = nn.BatchNorm2d(64)\n",
        "    self.conv4 = nn.Conv2d(64,128,kernel_size = 3, stride = 1)\n",
        "    self.bn4 = nn.BatchNorm2d(128)\n",
        "    self.fc1 = nn.Linear(10*10*128, 512)\n",
        "    self.fc2 = nn.Linear(512,256)\n",
        "    self.fc3 = nn.Linear(256,action_size)\n",
        "\n",
        "  def forward(self,state):\n",
        "    x = F.relu(self.bn1(self.conv1(state)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    x = F.relu(self.bn4(self.conv4(x)))\n",
        "    x = x.view(x.size(0),-1)#flatten the layer expect hte first dimension as it is getting decomposed to it\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return self.fc3(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "o-BXXNpiD4Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Training the AI"
      ],
      "metadata": {
        "id": "rUvCfE_mhwo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the environment"
      ],
      "metadata": {
        "id": "WWCDPF22lkwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make('MsPacmanDeterministic-v0', full_action_space = False)\n",
        "state_shape = env.observation_space.shape\n",
        "state_size = env.observation_space.shape[0]\n",
        "number_actions = env.action_space.n\n",
        "print('State shape: ', state_shape)\n",
        "print('State size: ', state_size)\n",
        "print('Number of actions: ', number_actions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FET1PXl6PS9R",
        "outputId": "c5c9d4ee-9043-4926-e599-b97bf8c9bb5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameNotFound",
          "evalue": "Environment `MsPacmanDeterministic` doesn't exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a900c4248034>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgymnasium\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MsPacmanDeterministic-v0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_action_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstate_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstate_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnumber_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0menv_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(env_id)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menv_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0m_check_version_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         raise error.Error(\n\u001b[1;32m    529\u001b[0m             \u001b[0;34mf\"No registered env with id: {env_name}. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0m_check_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0msuggestion_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\" Did you mean: `{suggestion[0]}`?\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     raise error.NameNotFound(\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0;34mf\"Environment `{name}` doesn't exist{namespace_msg}.{suggestion_msg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     )\n",
            "\u001b[0;31mNameNotFound\u001b[0m: Environment `MsPacmanDeterministic` doesn't exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the hyperparameters"
      ],
      "metadata": {
        "id": "Bx6IdX3ciDqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 5e-4\n",
        "minibatch_size = 64\n",
        "discount_factor = 0.99\n",
        "# replay_buffer_size = int(1e5)\n",
        "# interpolation_parameter = 1e-3"
      ],
      "metadata": {
        "id": "8zQMdHqHRX41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the frames"
      ],
      "metadata": {
        "id": "U2bDShIEkA5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "  frame = Image.fromarray(frame)\n",
        "  preprocess = transforms.Compose([transforms.Resize((128,128)),transforms.ToTensor()])\n",
        "  return preprocess(frame).unsqueeze(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "mrpSsPfBVK8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing the DCQN class"
      ],
      "metadata": {
        "id": "imMdSO-HAWra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "\n",
        "  def __init__(self, action_size):\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.action_size = action_size\n",
        "    self.local_qnetwork = Network( action_size).to(self.device)\n",
        "    self.target_qnetwork = Network( action_size).to(self.device)\n",
        "    self.optimizer = optim.Adam(self.local_qnetwork.parameters(), lr = learning_rate)\n",
        "    self.memory = deque(maxlen = 10000)\n",
        "\n",
        "  def step(self, state, action, reward, next_state, done):\n",
        "    state = preprocess_frame(state)\n",
        "    next_state = preprocess_frame(next_state)\n",
        "    self.memory.append((state, action, reward, next_state, done))\n",
        "    if len(self.memory) > minibatch_size:\n",
        "      experiences = random.sample(self.memory, k = minibatch_size)\n",
        "      self.learn(experiences, discount_factor)\n",
        "\n",
        "  def act(self, state, epsilon = 0.):\n",
        "    state = preprocess_frame(state).to(self.device)\n",
        "    self.local_qnetwork.eval()\n",
        "    with torch.no_grad():\n",
        "      action_values = self.local_qnetwork(state)\n",
        "    self.local_qnetwork.train()\n",
        "    if random.random() > epsilon:\n",
        "      return np.argmax(action_values.cpu().data.numpy())\n",
        "    else:\n",
        "      return random.choice(np.arange(self.action_size))\n",
        "\n",
        "  def learn(self, experiences, discount_factor):\n",
        "    states,actions, rewards,next_states, dones = zip(*experiences)\n",
        "\n",
        "    states = torch.from_numpy(np.vstack(states)).float().to(self.device)\n",
        "    actions = torch.from_numpy(np.vstack(actions)).long().to(self.device)\n",
        "    rewards = torch.from_numpy(np.vstack(rewards)).float().to(self.device)\n",
        "    next_states = torch.from_numpy(np.vstack(next_states)).float().to(self.device)\n",
        "    dones = torch.from_numpy(np.vstack(dones).astype(np.uint8)).float().to(self.device)\n",
        "\n",
        "    next_q_targets = self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "    q_targets = rewards + discount_factor * next_q_targets * (1 - dones)\n",
        "    q_expected = self.local_qnetwork(states).gather(1, actions)\n",
        "    loss = F.mse_loss(q_expected, q_targets)\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "-kRe2b8WdMTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the DCQN agent"
      ],
      "metadata": {
        "id": "yUg95iBpAwII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(number_actions)"
      ],
      "metadata": {
        "id": "ZqbcCXEQifTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the DCQN agent"
      ],
      "metadata": {
        "id": "CK6Zt_gNmHvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "number_episodes = 2000\n",
        "maximum_number_timesteps_per_episode = 10000\n",
        "epsilon_starting_value  = 1.0\n",
        "epsilon_ending_value  = 0.01\n",
        "epsilon_decay_value  = 0.995\n",
        "epsilon = epsilon_starting_value\n",
        "scores_on_100_episodes = deque(maxlen = 100)\n",
        "\n",
        "for episode in range(1, number_episodes + 1):\n",
        "  state, _ = env.reset()\n",
        "  score = 0\n",
        "  for t in range(maximum_number_timesteps_per_episode):\n",
        "    action = agent.act(state, epsilon)\n",
        "    next_state, reward, done, _, _ = env.step(action)\n",
        "    agent.step(state, action, reward, next_state, done)\n",
        "    state = next_state\n",
        "    score += reward\n",
        "    if done:\n",
        "      break\n",
        "  scores_on_100_episodes.append(score)\n",
        "  epsilon = max(epsilon_ending_value, epsilon_decay_value * epsilon)\n",
        "  print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)), end = \"\")\n",
        "  if episode % 100 == 0:\n",
        "    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)))\n",
        "  if np.mean(scores_on_100_episodes) >= 500.0:\n",
        "    print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode - 100, np.mean(scores_on_100_episodes)))\n",
        "    torch.save(agent.local_qnetwork.state_dict(), 'checkpoint.pth')\n",
        "    break"
      ],
      "metadata": {
        "id": "bAK07LlFivew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Visualizing the results"
      ],
      "metadata": {
        "id": "-0WhhBV8nQdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb9nVvU2Okhk"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import imageio\n",
        "from IPython.display import HTML, display\n",
        "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
        "\n",
        "def show_video_of_model(agent, env_name):\n",
        "    env = gym.make(env_name, render_mode='rgb_array')\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    frames = []\n",
        "    while not done:\n",
        "        frame = env.render()\n",
        "        frames.append(frame)\n",
        "        action = agent.act(state)\n",
        "        state, reward, done, _, _ = env.step(action)\n",
        "    env.close()\n",
        "    imageio.mimsave('video.mp4', frames, fps=30)\n",
        "\n",
        "show_video_of_model(agent, 'MsPacmanDeterministic-v0')\n",
        "\n",
        "def show_video():\n",
        "    mp4list = glob.glob('*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        display(HTML(data='''<video alt=\"test\" autoplay\n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "    else:\n",
        "        print(\"Could not find video\")\n",
        "\n",
        "show_video()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}